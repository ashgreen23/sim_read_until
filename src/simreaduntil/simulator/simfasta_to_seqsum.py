"""
Convert a FASTA file generated by the ONTSimulator into a sequencing_summary.txt file, based on the FASTA headers.

It contains the most relevant fields in the sequencing summary file. In particular, it converts the end reason to the ONT format and adds some extra columns
"""

import argparse
import os
from pathlib import Path
import sys
import typing
import warnings
from Bio import SeqIO
import numpy as np
import pandas as pd
import tqdm
from simreaduntil.shared_utils.debugging_helpers import is_test_mode
from simreaduntil.shared_utils.dna import get_nb_fasta_seqs
from simreaduntil.shared_utils.logging_utils import add_comprehensive_stream_handler_to_logger, setup_logger_simple
from simreaduntil.shared_utils.nanosim_parsing import NanoSimId
from simreaduntil.shared_utils.utils import print_args

from simreaduntil.simulator.channel_element import ReadDescriptionParser, ReadTags, end_reason_to_ont_map
from simreaduntil.simulator.readswriter import ReadsWriter

logger = setup_logger_simple(__name__)
"""module logger"""

_extra_fields = ["nb_ref_bps_full", "stopped_receiving", "never_requested"]
SEQ_SUMMARY_HEADER = ["read_id", "channel", "mux", "start_time", "duration", "passes_filtering", "template_start", "template_duration", "sequence_length_template", "end_reason"] + _extra_fields
"""Fields in the sequencing summary file"""

"""Write the sequencing summary header"""
def write_seqsum_header(seqsummary_file):
    seqsummary_file.write("\t".join(SEQ_SUMMARY_HEADER) + os.linesep)
    
"""
Writes a single sequence record to a sequencing summary file

Args:
    record: sequence record
    seqsummary_file: file to write to
    read_id: if None, will be parsed from description (by splitting on the first whitespace)
        Typically, when SeqIO.SeqRecord is constructed in the code, read_id must be set because the description does not contain the read id
        If it is read from a file with SeqIO.parse, the read_id is also in the description
"""
def write_seqsum_record_line(record: SeqIO.SeqRecord, seqsummary_file: typing.IO, read_id: str = None):
    if (read_id is None) or record.description.startswith(record.id):
        # id is in description
        read_id, description = record.description.split(" ", maxsplit=1)
    else:
        description = record.description
    
    parsed_desc = ReadDescriptionParser(description)
    if NanoSimId.is_valid(parsed_desc.full_read_id):
        full_len = NanoSimId.from_str(parsed_desc.full_read_id).ref_len # length if read had not been rejected
    else:
        full_len = np.NaN
    
    t_duration = parsed_desc.t_end - parsed_desc.t_start
    template_duration = t_duration - parsed_desc.t_delay
    if len(record.seq) == 0:
        logger.info(f"Found read '{read_id}' that stopped after time {t_duration} before its actual content would have started (at {parsed_desc.t_delay}), skipping") # due to adapters, barcodes
        return
    channel = parsed_desc.ch
    
    mux = 1
    passes_filtering = True
    print("\t".join(map(str, 
        [read_id, channel, mux, parsed_desc.t_start, t_duration, passes_filtering, parsed_desc.t_start + parsed_desc.t_delay, 
        template_duration, len(record.seq), end_reason_to_ont_map[parsed_desc.ended], full_len, ReadTags.RU_STOPPED_RECEIVING in parsed_desc.tags, ReadTags.RU_NEVER_REQUESTED in parsed_desc.tags]
    )), file=seqsummary_file)
    
class SequencingSummaryWriter(ReadsWriter):
    """
    Write the sequencing summary to a single file on-the-fly.
    
    Args:
        reads_out_fh: filehandler to write to
    """
    def __init__(self, reads_out_fh=sys.stdout):
        super().__init__()
        
        self.fh = reads_out_fh
        
        write_seqsum_header(self.fh)
        
    # Flush reads, e.g. write outstanding reads to file by flushing the file handler
    def _flush(self):
        self.fh.flush()
    
    def __repr__(self):
        return f"SequencingSummaryWriter(filename='{self.fh.name}')"
    
    # write read to file
    def _write_read(self, read: SeqIO.SeqRecord):
        write_seqsum_record_line(read, self.fh, read_id=read.id)
        
    def finish(self):
        if self.fh not in [sys.stdout, sys.stderr]:
            self.fh.close()
        else:
            self.fh.flush()
            
def convert_simfasta_to_seqsum(reads_fasta, seqsummary_filename, mode="w", tqdm_outer=False):
    """
    Convert FASTA generated by simulator to a sequencing summary file
    
    The FASTA contains enough metadata to populate the essential fields.
    If the read has a NanoSim id, it is used to get the full length of the read (before rejection).
    
    Note: The sequencing summary file may not be sorted by channel and time.
    """
    
    # "nb_ref_bps_full": number of basepairs of full read, relevant when it was rejected,
    # "stopped_receiving": whether readuntil set it to stop receiving
    # "never_requested": whether read until never requested it
    
    assert mode in ["a", "w"]
    with open(seqsummary_filename, mode=mode) as seqsummary_file:
        if mode == "w":
            write_seqsum_header(seqsummary_file)
        
        nb_seqs = get_nb_fasta_seqs(reads_fasta)
        if nb_seqs == 0:
            logger.warning(f"Empty FASTA file: '{Path(reads_fasta).resolve()}'")
        
        # set leave=False since progress bar is otherwise not properly erased
        for record in tqdm.tqdm(SeqIO.parse(reads_fasta, "fasta"), desc="Reading fasta line", leave=not tqdm_outer, total=nb_seqs):
            write_seqsum_record_line(record, seqsummary_file)
            # print(record)
            # break
            
def convert_simfasta_dir_to_seqsum(reads_dir, seqsummary_filename):
    """
    Convert a directory of fasta files (non-recursive) from the simulator to a sequencing summary file, first sorting fasta files by creation time
    """
    at_least_one_file = False
    open(seqsummary_filename, mode="w").close() # make seqsum file empty
    for (i, file) in enumerate(tqdm.tqdm(sorted(Path(reads_dir).glob("*.fasta"), key=lambda file: file.stat().st_ctime), desc="Converting FASTA files to sequencing summary")):
        at_least_one_file = True
        convert_simfasta_to_seqsum(file, seqsummary_filename, mode="w" if i == 0 else "a", tqdm_outer=True)
    if not at_least_one_file:
        warnings.warn(f"Found no FASTA files in directory {reads_dir}")

def main():
    """
    CLI entrypoint to convert a FASTA file generated by the ONTSimulator into a sequencing_summary.txt file, based on the FASTA headers.
    """
    add_comprehensive_stream_handler_to_logger()
    
    if is_test_mode():
        args = argparse.Namespace()
        # args.reads_fasta = Path("~/ont_project_all/ont_project/runs/replicate_run/reads.fasta").expanduser()
        args.reads_fasta = Path("~/ont_project_all/ont_project/runs/replicate_run").expanduser()
        args.seqsummary_filename = None
        
    else:
        parser = argparse.ArgumentParser(description="Convert a FASTA generated by the simulator to a sequencing_summary.txt file (with the most important columns)")
        parser.add_argument("reads_fasta", type=Path, help="FASTA file with reads, either a single file or a directory of files")
        parser.add_argument("--seqsummary_filename", type=Path, default=None, help="sequencing_summary.txt file to write, default: same directory as reads_fasta")

        args = parser.parse_args()
        print_args(args, logger=logger)
    
    seqsummary_filename = args.seqsummary_filename
    if args.seqsummary_filename is None:
        seqsummary_filename = args.reads_fasta.parent / "sequencing_summary.txt"
    
    # args.reads_fasta = "runs/selseq_run/reads/reads.fasta"
    # args.seqsummary_filename = "runs/selseq_run/sequencing_summary.txt"
    if Path(args.reads_fasta).is_dir():
        convert_simfasta_dir_to_seqsum(args.reads_fasta, seqsummary_filename)
    else:
        convert_simfasta_to_seqsum(args.reads_fasta, seqsummary_filename)
    
    logger.info("Done with fasta to seqsum conversion script")


if __name__ == "__main__":
    main()
